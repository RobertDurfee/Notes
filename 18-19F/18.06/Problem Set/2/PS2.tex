\documentclass{article}
\usepackage{tikz}
\usepackage{float}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{indentfirst}
\usepackage{siunitx}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {Images/} }
\usepackage{float}
\usepackage{mhchem}
\usepackage{chemfig}
\allowdisplaybreaks

\title{18.06 Problem Set 2}
\author{Robert Durfee}
\date{September 19, 2018}

\begin{document}

\maketitle

\section*{Problem 1}

\textit{For the matrix $ A $ and vector $ b $,}
\[
    A = \begin{pmatrix}
        1 & 2 & 1 & -1 & 1 \\
        1 & 0 & 1 & -1 & 0 \\
        1 & 2 & 1 & 0 & 0 \\
        1 & 1 & 0 & 0 & 0 \\
        -1 & 0 & 0 & 0 & 0
    \end{pmatrix},
    \ b = \begin{pmatrix}
        0 \\
        0 \\
        0 \\
        0 \\
        1
    \end{pmatrix}
\]

\subsection*{Part A}

\textit{Show hand calculations to compute $ x = A^{-1} b $}

\bigbreak

Applying forward substitution
\begin{align*}
    -1 x_1 = 1 \implies x_1 &= -1 \\
     x_1 + x_2 = 0 \implies x_2 &= 1 \\
     x_1 + 2 x_2 + x_3 = 0 \implies x_3 &= -1 \\
     x_1 + x_3 - x_4 = 0 \implies x_4 &= -2 \\
     x_1 + 2 x_2 + x_3 - x_4 + x_5 = 0 \implies x_5 &= -2
\end{align*}

\subsection*{Part B}

\textit{Explain why your $ x $ appears in $ A^{-1} $.}

\bigbreak

The vector $ \vec{b} $ simply selects the last column of any matrix multiplied
to it on the left. Therefore, since $ x = A^{-1} b $, the vector $ \vec{x} $
must be the last column of $ A^{-1} $.

\section*{Problem 2}

\textit{Consider the matrix}
\[
    A = \begin{pmatrix}
        1 & 4 & 1 \\
        1 & 2 & -1 \\
        3 & 14 & 6
    \end{pmatrix}
\]
\textit{In this problem, we will consider transforming this matrix by a sequence
of invertible linear column operations - multiplying columns by scalars and
adding/subtracting them.}

\subsection*{Part A}

\textit{Come up with column operations that change the first row from
$\begin{pmatrix} 1 & 4 & 1\end{pmatrix}$ to $\begin{pmatrix} 1 & 0 &
0\end{pmatrix}$, i.e. that put zeros to the *right* of the first pivot. Express
these operations in terms of multipling $A$ on the left or right by some matrix
$E$. Give $E$ and $E^{-1}$.}

\bigbreak

\[
    \begin{pmatrix}
        1 & 4 & 1 \\
        1 & 2 & -1 \\
        3 & 14 & 6
    \end{pmatrix}
    \begin{pmatrix}
        1 & -4 & -1 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & 0 & 0 \\
        1 & -2 & -2 \\
        3 & 2 & 3
    \end{pmatrix}
\]
Therefore
\[
    E = \begin{pmatrix}
        1 & -4 & -1 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix},
    \ E^{-1} = \begin{pmatrix}
        1 & 4 & 1 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
\]

\subsection*{Part B}

\textit{If we do a sequence of column operations that transform $A$ into $I$,
and then do the same column operations to the $3\times 3$ identity matrix $I$,
what is the resulting matrix?}

\bigbreak

The resulting matrix should be the inverse of matrix $ A $.

\subsection*{Part C}

\textit{Carry out the process from (b): perform column operations on $A$ that
transform it into $I$, and perform the *same* column operations on $I$. Do them
both at once by "augmenting" $A$ in a certain way (maybe not the usual way).}

\bigbreak

Picking up from previous step in Part A
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        1 & -2 & -2 \\
        3 & 2 & 3
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        1/2 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -2 & 0 \\
        4 & 2 & 1
    \end{pmatrix}
\]
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -2 & 0 \\
        4 & 2 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -2 & 0 \\
        -4 & -2 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -2 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
\]
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -2 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -1/2 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
\]

Now applying in reverse
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & -4 & 1 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & -4 & -1 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
\]
\[
    \begin{pmatrix}
        1 & -4 & -1 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & -1 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & -4 & 3 \\
        0 & 1 & -1 \\
        0 & 0 & 1
    \end{pmatrix}
\]
\[
    \begin{pmatrix}
        1 & -4 & 3 \\
        0 & 1 & -1 \\
        0 & 0 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        1/2 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        -1 & -4 & 3 \\
        1/2 & 1 & -1 \\
        0 & 0 & 1
    \end{pmatrix}
\]
\[
    \begin{pmatrix}
        -1 & -4 & 3 \\
        1/2 & 1 & -1 \\
        0 & 0 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        -4 & -2 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        -13 & -10 & 3 \\
        9/2 & 3 & -1 \\
        -4 & -2 & 1
    \end{pmatrix}
\]
\[
    \begin{pmatrix}
        -13 & -10 & 3 \\
        9/2 & 3 & -1 \\
        -4 & -2 & 1
    \end{pmatrix}
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & -1/2 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
        -13 & 5 & 3 \\
        9/2 & -3/2 & -1 \\
        -4 & 1 & 1
    \end{pmatrix}
\]

\section*{Problem 3}

\textit{Compute $L$ and $U$ for the following symmetric matrix $A$:}

\[
    A = \begin{pmatrix}
        a & a & a & a \\
        a & b & b & b \\
        a & b & c & c \\
        a & b & c & d
    \end{pmatrix}
\]

\textit{and find four conditions on the numbers $a$,$b$,$c$, and $d$ to get
$A=LU$ with four pivots.}

\bigbreak

Applying $ R2 - R1 $, $R3 - R1 $, $ R4 - R1 $.
\[
    \begin{pmatrix}
        a & a & a & a \\
        0 & b - a & b - a & b - a \\
        0 & b - a & c - a & c - a \\
        0 & b - a & c - a & d - a
    \end{pmatrix}
\]
Applying $ R3 - R2 $ and $ R4 - R2 $.
\[
    \begin{pmatrix}
        a & a & a & a \\
        0 & b - a & b - a & b - a \\
        0 & 0 & c - b & c - b \\
        0 & 0 & c - b & d - b
    \end{pmatrix}
\]
Applying $ R4 - R3 $.
\[
    \begin{pmatrix}
        a & a & a & a \\
        0 & b - a & b - a & b - a \\
        0 & 0 & c - b & c - b \\
        0 & 0 & 0 & d - c
    \end{pmatrix}
\]
Therefore, in order for there to be four pivots,
$$ a \neq 0,\ b - a \neq 0,\ c - b \neq 0,\ d - c \neq 0 $$

\section*{Problem 4}

\textit{Consider the following matrix for some numbers $a$, $b$, and $c$:}

\[
    L = \begin{pmatrix}
        1 & 0 & 0 \\
        a & 1 & 0 \\
        b & c & 1
    \end{pmatrix}
\]

\subsection*{Part A}

\textit{When you perform the usual Gaussian elimination steps to $L$, what
matrix will you obtain?}

\bigbreak

Applying $ R2 - a R1 $ and $ R3 - b R1 $.
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & c & 1
    \end{pmatrix}
\]
Applying $ R3 - c R2 $.
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
\]

\subsection*{Part B}

\textit{If you apply the same row operations to $I$, what matrix will you get?}

\bigbreak

Starting with the identity matrix
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
\]
Applying $ R2 - a R1 $ and $ R3 - b R1 $.
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        -a & 1 & 0 \\
        -b & 0 & 1
    \end{pmatrix}
\]
Applying $ R3 - c R2 $.
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        -a & 1 & 0 \\
        ca - b & -c & 1
    \end{pmatrix}
\]

\subsection*{Part C}

\textit{If you apply the same row operations to $LB$ for some $3\times n$
matrix $B$, what will you get?}

\bigbreak

Multiplying the given matrix by a unknown $ 3 \times 4 $ matrix
\[
    \begin{pmatrix}
        1 & 0 & 0 \\
        a & 1 & 0 \\
        b & c & 1
    \end{pmatrix}
    \begin{pmatrix}
        u_{11} & u_{12} & u_{13} & u_{14} \\
        u_{21} & u_{22} & u_{23} & u_{24} \\
        u_{31} & u_{32} & u_{33} & u_{34} \\
    \end{pmatrix}
\]
Which results in
\[
    \begin{pmatrix}
        u_{11} & u_{12} & u_{13} & u_{14} \\
        a u_{11} + u_{21} & a u_{12} + u_{22} & a u_{13} + u_{23} & a u_{14} + u_{24} \\
        b u_{11} + c u_{21} + u_{31} & b u_{12} + c u_{22} + u_{32} & b u_{13} + c u_{23} + u_{33} & b u_{14} + c u_{24} + u_{34}
    \end{pmatrix}
\]
Performing row operations $ R2 - a R1 $, $ R3 - b R1 $, and $ R3 - c R2 $ will
reduce this back to the original unknown matrix $ B $.

\section*{Problem 5}

\textit{Consider the following matrices:}
$$
U = \begin{pmatrix} 1 & 1 & -1 \\ 0 & 1 & 2 \\ 0 & 0 & 1 \end{pmatrix}, \;
L = \begin{pmatrix} 1 & 0 & 0 \\ -1 & 1 & 0 \\ -2 & 1 & 1 \end{pmatrix}, \;
B = \begin{pmatrix} 1 & 2 & 3 \\ 3 & 2 & 1 \\ 1 & 0 & 1 \end{pmatrix}
$$

\textit{Let $A = U B^{-1} L$.}

\subsection*{Part A}

\textit{Compute the second column of $A^{-1}$.}

\bigbreak

The given expression $ A = U B^{-1} L $ can be rewritten using the inverse
product rule
$$ A^{-1} = L^{-1} B U^{-1} $$
Let $ C = L^{-1} B $. Using row reduction, $ C $ is determined
\[
    C = \begin{pmatrix}
        1 & 2 & 3 \\
        4 & 4 & 4 \\
        -1 & 0 & 3
    \end{pmatrix}
\]
Using the column wise definition of matrix multiplication,
$$ a_2^{-1} = C u_2^{-1} $$
The definition of identities gives
$$ U u_2^{-1} = e_2 $$
Using row reduction, $ u_2^{-1} $ can be determined.
\[
    u_2^{-1} = \begin{pmatrix}
        -1 \\
        1 \\
        0
    \end{pmatrix}
\]
Substituting back to solve for second column of $ A^{1} $
\[
    a_2^{-1} = \begin{pmatrix}
        1 & 2 & 3 \\
        4 & 4 & 4 \\
        -1 & 0 & 3
    \end{pmatrix}
    \begin{pmatrix}
        -1 \\
        1 \\
        0
    \end{pmatrix}
    = \begin{pmatrix}
        1 \\
        0 \\
        1
    \end{pmatrix}
\]

\section*{Problem 6}

\textit{Suppose you have a $5 \times 5$ matrix of the form}
$$A = \begin{pmatrix}
    \star & \star & 0 & 0 & 0 \\
    \star & \star & \star & 0 & 0 \\
    0 & \star & \star & \star & 0 \\
    0 & 0 & \star & \star & \star \\
    0 & 0 & 0 & \star & \star
\end{pmatrix}
$$
\textit{where "$\star$" denotes nonzero entries.}

\subsection*{Part A}

\textit{Assuming no row swaps are required and the matrix is nonsingular, what
pattern of nonzero entries do you generically expect to see in the $L$ and
$U$ factors of a matrix $A$ of this form, and why?}

\bigbreak

Each column in a tridiagonal matrix only needs to complete one row operation to
eliminate the element directly below the pivot point. Therefore, the $ L $
pattern should be
\[
    L = \begin{pmatrix}
        1 & 0 & 0 & 0 \\
        \star & 1 & 0 & 0 \\
        0 & \star & 1 & 0 \\
        0 & 0 & \star & 1
    \end{pmatrix}
\]

Furthermore, since each column only has one element directly above the pivot,
and all the above elements are zeros, they will be unaffected by row elimination
steps. Therefore, the $ U $ pattern should be
\[
    U \begin{pmatrix}
        \star & \star & 0 & 0 \\
        0 & \star & \star & 0 \\
        0 & 0 & \star & \star \\
        0 & 0 & 0 & \star
    \end{pmatrix}
\]

\subsection*{Part B}

\textit{If $A$ is an $m \times m$ tridiagonal matrix (i.e. same pattern of
zeros, but extended to an arbitrary size), how does the count of scalar
arithmetic operations to compute the $ L $, $U$ factors (i.e. to perform
elimination) scale with $m$?  You need not give an exact count, just say whether
it is roughly proportional to $m$, $m^2$, $m^3$, etcetera for large $m$.)}

\bigbreak

Since each column only has one nonzero element below the pivot, it only takes
one row operation to make zero below each pivot. In this row operation, only
four elements are involved. Therefore, there are 2 scalar multiplications and
additions. Thus, each column requires constant time to perform row reduction.
Since there are $ m $ columns, the number of scalar operations is roughly
proportional to $ m $.

\end{document}

