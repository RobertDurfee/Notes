\documentclass{article}
\usepackage{tikz}
\usepackage{float}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{indentfirst}
\usepackage{siunitx}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {Images/} }
\usepackage{float}
\usepackage{mhchem}
\usepackage{chemfig}
\allowdisplaybreaks

\title{18.06 Problem Set 5}
\author{Robert Durfee}
\date{October 10, 2018}

\begin{document}

\maketitle

\section*{Problem 1}

\textit{In pset 4, problem 4, you considered the matrix}
$$ A = \begin{pmatrix}
    0 & 1 & 2 & 3 & 4 \\
    0 & 1 & 2 & 4 & 6 \\
    0 & 0 & 0 & 1 & 2
\end{pmatrix} $$

\subsection*{Part A}

\textit{Find a basis for the row space $C(A^T)$.}

\bigbreak

Performing row operations to row-echelon form
$$ \begin{pmatrix}
    0 & 1 & 2 & 0 & -2 \\
    0 & 0 & 0 & 1 & 2 \\
    0 & 0 & 0 & 0 & 0
\end{pmatrix} $$
Since row operations do not change the row space, the basis for the row space
is given by the non-zero rows.
$$ C(A^T) = \left\{ \begin{pmatrix}
    0 \\
    1 \\
    2 \\
    0 \\
    -2
\end{pmatrix},\, \begin{pmatrix}
    0 \\
    0 \\
    0 \\
    1 \\
    2
\end{pmatrix} \right\} $$

\subsection*{Part B}

\textit{Find a basis for the left nullspace $N(A^T)$. Use the fact that
$N(A^T) = C(A)^\perp$ to obtain a condition for $Ax=c$ to be solvable for a
vector $c = \begin{pmatrix} c_1 & c_2 & c_3 \end{pmatrix}^T$.}

\bigbreak

The transpose of $ A $ is
$$ A^T = \begin{pmatrix}
    0 & 0 & 0 \\
    1 & 1 & 0 \\
    2 & 2 & 0 \\
    3 & 4 & 1 \\
    4 & 6 & 2
\end{pmatrix} $$
Performing row operations to reduced row-echelon form
$$ \begin{pmatrix}
    1 & 0 & -1 \\
    0 & 1 & 1 \\
    0 & 0 & 0 \\
    0 & 0 & 0 \\
    0 & 0 & 0
\end{pmatrix} $$
The constraint for when this equals zero is given by
$$ x_1 - x_3 = 0 $$
$$ x_2 + x_3 = 0 $$
Therefore, the left null space is given by the basis
$$ N(A^T) = \left\{ \begin{pmatrix}
    1 \\
    -1 \\
    1
\end{pmatrix} \right\} $$
Since $ N(A^T) = C(A)^\perp $, any vector, $c$, perpendicular to all vectors
in the left null space will be in the column space and therefore will make $
Ax = c $ solvable. For $c$ to be perpendicular to all the vectors in the left
null space, the following condition must be met
$$ \begin{pmatrix}
    1 \\
    -1 \\
    0
\end{pmatrix} \cdot \begin{pmatrix}
    c_1 \\
    c_2 \\
    c_3
\end{pmatrix} = 0 $$
Which is the same as 
$$ c_1 - c_2 + c_3 = 0 $$

\subsection*{Part C}

\textit{In pset 4, you considered the vector $b = \begin{pmatrix} 3 & 6 & 
\beta \end{pmatrix}^T$ and found that $Ax=b$ only had a solution if $\beta =
3$. Check that this condition also follows from your answer in (b).}

\bigbreak

Filling in the constraint from above
$$ 3 - 6 + \beta = 0 $$
Yields $ \beta = 3 $. Therefore, this is the same answer as determined
before.

\section*{Problem 2}

\textit{The set of $2\times 2$ real matrices form a vector space
$\mathbb{R}^{2\times2}$. One possible basis for this vector space is the
following set of 4 matrices:}
$$ M_1 = \begin{pmatrix}
    1 & 0 \\
    0 & 0
\end{pmatrix}, \; M_2 = \begin{pmatrix}
    0 & 0 \\
    1 & 0
\end{pmatrix}, \; M_3 = \begin{pmatrix}
    0 & 1 \\
    0 & 0
\end{pmatrix}, \; M_4 = \begin{pmatrix}
    0 & 0 \\
    0 & 1
\end{pmatrix}. $$
\textit{That is, we can write any $A \in \mathbb{R}^{2\times2}$ as $A = a_1
M_1 + a_2 M_2 + a_3 M_3 + a_4 M_4$ for $a = \begin{pmatrix} a_1 & a_2 & a_3
& a_4 \end{pmatrix}^T$: representing matrices $A$ by vectors $a \in
\mathbb{R}^4$!}

\textit{Given any $2\times 2$ matrices}
$$ B = \begin{pmatrix}
    b_{11} & b_{12} \\
    b_{21} & b_{22}
\end{pmatrix}, \; C = \begin{pmatrix}
    c_{11} & c_{12} \\
    c_{21} & c_{22}
\end{pmatrix}, $$
\textit{we can define a linear transformation $T(A) = BAC$ that takes a
matrix $A \in \mathbb{R}^{2\times2}$ and gives you another matrix in
$\mathbb{R}^{2\times2}$.}

\subsection*{Part A}

\textit{Write this $T(A)$ using the basis $\{ M_1, M_2, M_3, M_4 \}$ as a
single matrix $D$ multipying the vector $a$ corresponding to $A$. Start by
expressing your $D$ as the product of two matrices (one representing
multipling on the left by $B$ and the other representing multiplying on the
right by $C$), and then multiply them to give a formula for $D$.}

\bigbreak

First, looking at the matrix product $ BA $. Written in the basis described
above, this is the same as
$$ BA = \begin{pmatrix}
    b_{11} a_{11} + b_{12} a_{21} \\
    b_{21} a_{11} + b_{22} a_{21} \\
    b_{11} a_{21} + b_{12} a_{22} \\
    b_{21} a_{21} + b_{22} a_{22}
\end{pmatrix} = D_1 \begin{pmatrix}
    a_{11} \\
    a_{21} \\
    a_{12} \\
    a_{22}
\end{pmatrix} $$
Where $ D_1 $ is defined as
$$ D_1 = \begin{pmatrix}
    b_{11} & b_{12} & 0 & 0 \\
    b_{21} & b_{22} & 0 & 0 \\
    0 & 0 & b_{11} & b_{12} \\
    0 & 0 & b_{21} & b_{22}
\end{pmatrix} $$

Now, looking at the matrix product $ AC $. Written in the basis described
above, this is the same as 
$$ AC = \begin{pmatrix}
    a_{11} c_{11} + a_{12} c_{21} \\
    a_{21} c_{11} + a_{22} c_{21} \\
    a_{11} c_{12} + a_{12} c_{22} \\
    a_{21} c_{12} + a_{22} c_{22}
\end{pmatrix} = D_2 \begin{pmatrix}
    a_{11} \\
    a_{21} \\
    a_{12} \\
    a_{22}
\end{pmatrix} $$
Where $ D_2 $ is defined as
$$ D_2 = \begin{pmatrix}
    c_{11} & 0 & c_{21} & 0 \\
    0 & c_{11} & 0 & c_{21} \\
    c_{12} & 0 & c_{22} & 0 \\
    0 & c_{12} & 0 & c_{22}
\end{pmatrix} $$

Therefore, this linear transformation $ T(A) $ can be represented in the
basis provided as
$$ T(a) = D_1 D_2 a $$
Multiplying $ D_1 $ and $ D_2 $ will yield $ D $
$$ D = \begin{pmatrix}
    b_{11} c_{11} & b_{12} c_{11} & b_{11} c_{21} & b_{12} c_{21} \\
    b_{21} c_{11} & b_{22} c_{11} & b_{21} c_{21} & b_{22} c_{21} \\
    b_{11} c_{12} & b_{12} c_{12} & b_{11} c_{22} & b_{12} c_{22} \\
    b_{21} c_{12} & b_{22} c_{12} & b_{21} c_{22} & b_{22} c_{22}
\end{pmatrix} $$

\subsection*{Part C}

\textit{Look up the Kronecker product online, and show that $D$ can be
written in terms of a Kronecker product involving $B$ and $C$.}

\bigbreak

From the definition of $ D $ above, it is clear that it is the same as
$$ D = \begin{pmatrix}
    c_{11} \begin{pmatrix}
        b_{11} & b_{12} \\
        b_{21} & b_{22}
    \end{pmatrix} & c_{21} \begin{pmatrix}
        b_{11} & b_{12} \\
        b_{21} & b_{22}
    \end{pmatrix} \\
    c_{12} \begin{pmatrix}
        b_{11} & b_{12} \\
        b_{21} & b_{22}
    \end{pmatrix} & c_{22} \begin{pmatrix}
        b_{11} & b_{12} \\
        b_{21} & b_{22}
    \end{pmatrix}
\end{pmatrix} $$
Since the definition of the Kronecker product is
$$ X \otimes Y = \begin{pmatrix}
    x_{11} Y & x_{12} Y & \cdots & x_{1n} Y \\
    x_{21} Y & x_{22} Y & \cdots & x_{2n} Y \\
    \vdots & \vdots & \ddots & \vdots \\
    x_{m1} Y & x_{m2} Y & \cdots & x_{mn} Y
\end{pmatrix} $$
$ D $ can be written as the Kronecker product
$$ C^T \otimes B = D $$

\section*{Problem 3}

\textit{In this problem you will solve a nonlinear system of equations by the
multidimensional Newton algorithm.}

\textit{In particular, consider the system of equations $f(x) = 0$ where $x =
\begin{pmatrix} x_1 & x_2 \end{pmatrix}^T \in \mathbb{R}^2$ and}
$$ f(x) = \begin{pmatrix}
    1 / 2 \sin(x_1 x_2) - x_2 / 4 \pi - x_1 / 2 \\
    \left(1 - 1 / 4 \pi \right) \left(e^{2 x_1 - 1} - 1\right) + x_2 / \pi - 2x_1
\end{pmatrix} $$

\subsection*{Part B}

\textit{Compute one entry of the Jacobian matrix by hand and check that it
matches.}

\bigbreak

The general form of the Jacobian is
$$ J(\vec{x}) = \begin{pmatrix}
    1 / 2 \left( x_2 \cos(x_1 x_2) - 1 \right) & \left(2 \pi x_1 \cos (x_1 x_2) - 1 \right) / 4 \pi \\
    -2 & 2 \left(1 - 1 / 4 \pi \right) e^{2 x_2 - 1} + 1 / \pi
\end{pmatrix} $$

Let $ \vec{x} = \begin{pmatrix} 1 & 2 \end{pmatrix}^T $. Then the Jacobian at that
point is
$$ J \begin{pmatrix}
    1 \\
    2
\end{pmatrix} = \begin{pmatrix} 
    -0.92 & -0.29 \\
    -2.00 & 37.29
\end{pmatrix} $$

\subsection*{Part D}

\textit{Pick one of the roots that you see on the plot and set $ x $ to be
roughly the location of the root. How many iterations do you need for the
length $ \vert f(x) \vert $ to become less than $10^{-10}$?}

\bigbreak

Let $ x = \begin{pmatrix} 0 & 0 \end{pmatrix}^T $. It took approximately 5
iterations to become less than $ 10^{-10} $.

\section*{Problem 4}

\textit{The following is an important property of the very important matrix
$A^T A$ (for real matrices) that will come up several times in 18.06:}

\subsection*{Part A}

\textit{If $A^TAx=0$ then $Ax=0$. Reason: If $A^TAx=0$, then $Ax$ is in the
nullspace of $A^T$ and also in the (?) of $A$, and those spaces are
(?). Conclusion: $N(A^T A) = N(A)$.}

\bigbreak

If $A^TAx=0$, then $Ax$ is in the nullspace of $A^T$ and also in the
\textit{column space} of $A$, and those spaces are \textit{orthogonal}.
Conclusion: $N(A^T A) = N(A)$.

\subsection*{Part B}

\textit{Alternative proof: $A^TAx=0$, then $x^T A^T Ax = 0 = (Ax)^T (Ax)$.
Why does this imply that $Ax=0$? (Hint: if $y^Ty = 0$, can we have $y\ne
0$?)}

\bigbreak

Let $ Ax = y $. If $ y^T y = 0 $, this is the same as
$$ y_1^2 + y_2^2 + \ldots + y_n^2 = 0 $$
From this, since every square must be positive, it is clear that this is only
possible if every component of $ y $ is zero. Since $ y = Ax $, then every
component of $ Ax $ must be zero. Therefore, $ Ax = 0 $.

\section*{Problem 5}

\textit{Construct matrices with each of the following properties, or explain
why it is impossible:}

\subsection*{Part A}

\textit{Column space contains $\begin{pmatrix} 1 & 1 & 0 \end{pmatrix}^T $,
$\begin{pmatrix} 0 & 0 & 1 \end{pmatrix}^T$, and row space contains
$\begin{pmatrix} 1 & 2 \end{pmatrix}^T$, $\begin{pmatrix} 2 & 5
\end{pmatrix}^T$}

\bigbreak

An example of a matrix that satisfies this property could be
$$ \begin{pmatrix}
    1 & 2 \\
    1 & 2 \\
    2 & 5
\end{pmatrix} $$

\subsection*{Part B}

\textit{Column space has basis $\begin{pmatrix} 1 & 1 & 3 \end{pmatrix}$,
nullspace has basis $\begin{pmatrix} 3 & 1 & 1 \end{pmatrix}$}

\bigbreak

Assume for contradiction that there exists a matrix $ A $ that satisfies
the requirements provided. The column space has a dimension of 1. Therefore,
the rank of $ A $ is 1. Furthermore, the column space lies in $ \mathbb{R}^3
$. Thus, the number of rows in the matrix, $ m = 3 $.

The null space also has a dimension of 1 and lies in $ \mathbb{R}^3 $. From
the definition of null space, its dimension must be $ n - r $. Therefore, the
rank must be 2. However, this contradicts the rank determined from the column
space. Therefore, this is not possible.

\subsection*{Part C}

\textit{Dimension of nullspace = 1 + dimension of left nullspace}

\bigbreak

The dimension of the null space is $ n - r $ and the dimension of the left
null space is $ m - r $. From the requirement above,
$$ n - r = 1 + (m - r) $$
Therefore, this will occur whenever there is one more column than row. For
example, consider the simple matrix
$$ A = \begin{pmatrix}
    1 & 1 
\end{pmatrix} $$
The null space is
$$ N(A) = \left\{ \begin{pmatrix}
    -1 \\
    1
\end{pmatrix} \right\} $$
Which has a dimension of $ 1 $. The left null space, however, is
$$ N(A^T) = \left\{ \vec{0} \right\} $$
Which has a dimension of $ 0 $, thus, satisfying the requirement.

\subsection*{Part D}

\textit{Nullspace contains $\begin{pmatrix} 1 & 3 \end{pmatrix}^T$, column space
contains $\begin{pmatrix} 3 & 1 \end{pmatrix}^T$}

\bigbreak

From the first part of the requirement,
$$ \begin{pmatrix}
    a_{11} & a_{12} \\
    a_{21} & a_{22}
\end{pmatrix} \begin{pmatrix}
    1 \\
    3
\end{pmatrix} = \begin{pmatrix}
    0 \\
    0
\end{pmatrix} $$
Thus, the constraint
$$ a_{11} = -3 a_{12} $$
$$ a_{21} = -3 a_{22} $$

From the second part of the requirement,
$$ \begin{pmatrix}
    -3 a_{12} & a_{12} \\
    -3 a_{22} & a_{22}
\end{pmatrix} x = \begin{pmatrix}
    3 \\
    1
\end{pmatrix} $$
Thus the constraint
$$ a_{12} / a_{22} = 3 $$

From this, a possible matrix could be
$$ \begin{pmatrix}
    -9 & 3 \\
    -3 & 1
\end{pmatrix} $$

\subsection*{Part E}

\textit{Row space = column space, nullspace $\neq$ left nullspace.}

\bigbreak

Since the null space is perpendicular to the row space and the left null
space is perpendicular to the column space, if the column and row spaces are
equal, then their perpendicular subspaces must also be equal. Therefore, this
is impossible.

\section*{Problem 6}

\textit{Suppose S is spanned by (1,7,3) and (1,1,1). Then $S^\perp$ is the
nullspace of what matrix?}

\bigbreak

Since the null space of a matrix is perpendicular to the row space of that
matrix, $ S^\perp $ is the null space of the matrix whose row space is
spanned by $ S $.

\section*{Problem 7}

\textit{If a subspace $S$ is contained in a subspace $V$ ($S \subseteq V$),
then which of the following must be true? $S^\perp$ contains $V^\perp$ or
$V^\perp$ contains $S^\perp$? Why?}

\bigbreak

Let $ S \subseteq V \in \mathbb{R}^n $. Then their orthogonal sets are
defined
$$ S^\perp = \{ x \in \mathbb{R}^n \mid x \cdot s = 0\, \forall s \in S \} $$
$$ V^\perp = \{ x \in \mathbb{R}^n \mid x \cdot v = 0\, \forall v \in V \} $$

Now, let $ x \in V^\perp $. Then, by definition, $ x \cdot v = 0\, \forall v
\in V $. Now, since $ S \subseteq V $, let $ v \in S $. Then, $ x \in S^\perp
$ as well. From this, every vector in $ V^\perp $ must also be in $ S^\perp
$. Therefore, $ V^\perp \subseteq S^\perp $.

An alternative way of thinking about this is geometrically. Consider $ V $ to
be a plane in $ \mathbb{R}^3 $ and $ S $ to be a line within this plane.
Then, $ V^\perp $ is given by a line in $ \mathbb{R}^3 $ which is contained
in $ S^\perp $ which is a plane.

\end{document}