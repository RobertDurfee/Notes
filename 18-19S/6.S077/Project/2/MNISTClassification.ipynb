{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from timeit import default_timer as timer\n",
    "import warnings\n",
    "from utils import get_data_extract\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import LSHForest\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.nn import relu, softmax\n",
    "from tensorflow.train import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "\n",
    "## Problem 0\n",
    "\n",
    "Load the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = get_data_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "The dimensions of the data segments are as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images Shape: (16500, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Images Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Images Shape: (1500, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Images Shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images Shape: (3000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Images Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "The first two images in the training set are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Image:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADqFJREFUeJzt3X+MVPW5x/HPAwWjUuMP9iLhx926UaMxQJuR1KCmWttY0wT7hwgkBBO98AfobaxGopGa8A+5UQgG0wSupHDt5UdsiZgYWy4xasNN42i8qOVeRbNYENldbaxEBFee+8cemi3u+c4wc2bOwPN+JZudOc989zwZ/XBmzvfMfM3dBSCeUWU3AKAchB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDfaufOxo8f793d3e3cJRBKb2+vBgYGrJ7HNhV+M7tV0hpJoyX9u7uvTD2+u7tb1Wq1mV0CSKhUKnU/tuGX/WY2WtJTkn4i6WpJ88zs6kb/HoD2auY9/0xJ+9z9A3c/LmmLpNnFtAWg1ZoJ/yRJfxl2/0C27R+Y2SIzq5pZtb+/v4ndAShSy8/2u/s6d6+4e6Wrq6vVuwNQp2bCf1DSlGH3J2fbAJwBmgn/a5IuN7PvmNlYSXMl7SimLQCt1vBUn7sPmtlSSb/X0FTfBnd/p7DOALRUU/P87v6CpBcK6gVAG3F5LxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBtXWJbnSe48ePJ+vunqzv3r07Wb/llltOu6d63Xnnncn6M888k1sbNYrjHs8AEBThB4Ii/EBQhB8IivADQRF+ICjCDwTV1Dy/mfVK+lzS15IG3b1SRFM4PV999VVube3atcmxjzzySLJ+7NixZH306NHJ+pQpU5L1lIGBgWR927ZtyfqKFStyaz09PQ31dDYp4iKfm9w9/V8JQMfhZT8QVLPhd0l/MLPXzWxREQ0BaI9mX/Zf7+4HzeyfJO00s/9191eGPyD7R2GRJE2dOrXJ3QEoSlNHfnc/mP3uk7Rd0swRHrPO3SvuXunq6mpmdwAK1HD4zex8M/v2yduSfizp7aIaA9BazbzsnyBpu5md/Dv/6e4vFtIVgJZrOPzu/oGk6QX2ggYtX748t7Zhw4bk2CuuuCJZP+ecc5L1VatWJeuzZs1K1lMWLFiQrG/evDlZX716dW6t1vUPETDVBwRF+IGgCD8QFOEHgiL8QFCEHwiKr+4+C1x55ZW5tfvuuy85ttZHes9kL76Yf9nJkSNHkmPHjRtXdDsdhyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPP9ZIPWx2tTXekvSddddl6zffPPNDfXUCaZPz//Eea2PKkfAkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKe/ywwbdq03NqWLVuSY7dv356st3Kev9YS3Dt37kzWL7300mR95cqVubUxY8Ykx0bAkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgjJ3Tz/AbIOkn0rqc/drsm0XS9oqqVtSr6Q57v7XWjurVCperVabbBmnOnr0aG6tp6cnObavry9ZHxwcbKinkz777LPc2k033ZQcu2fPnmR9/vz5yfqmTZuS9bNRpVJRtVq1eh5bz5H/15JuPWXbMkm73P1ySbuy+wDOIDXD7+6vSPr0lM2zJW3Mbm+UdHvBfQFosUbf809w90PZ7Y8lTSioHwBt0vQJPx86aZB74sDMFplZ1cyq/f39ze4OQEEaDf9hM5soSdnv3LNG7r7O3SvuXunq6mpwdwCK1mj4d0hamN1eKOm5YtoB0C41w29mmyX9t6QrzeyAmd0taaWkH5nZe5Juye4DOIPU/Dy/u8/LKf2w4F7QoHPPPTe3tnz58uTYpUuXJuu1xi9blp7lnTlzZm7t/fffT46dNGlSsr5ixYpkHWlc4QcERfiBoAg/EBThB4Ii/EBQhB8Iiq/uPss1e1XlE088kaz39vYm66npvFpfvf3qq68m61OnTk3WkcaRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYp7/LHf77envVp0zZ06yvnXr1mT9+eefT9ZTX599xx13JMeyjHZrceQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCY5z8LHD9+PLe2ZMmS5Nha8/gnTpxI1mst8X7DDTfk1pjHLxdHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquY8v5ltkPRTSX3ufk227TFJ/yKpP3vYw+7+QquaPNsNDg4m619++WWynloG+913302OveCCC5L1WvP4R44cSdYff/zx3NqaNWuSY9Fa9Rz5fy3p1hG2r3b3GdkPwQfOMDXD7+6vSPq0Db0AaKNm3vMvNbM9ZrbBzC4qrCMAbdFo+H8lqUfSDEmHJOUu6GZmi8ysambV/v7+vIcBaLOGwu/uh939a3c/IWm9pNwzTu6+zt0r7l5pdtFIAMVpKPxmNnHY3Z9JeruYdgC0Sz1TfZsl/UDSeDM7IOmXkn5gZjMkuaReSYtb2COAFqgZfnefN8Lmp1vQyxnr4MGDyXqt+ewDBw4k69u2bUvWL7zwwtxarc/zP/DAA8n69u3bk/X7778/WX/55ZeTdZSHK/yAoAg/EBThB4Ii/EBQhB8IivADQfHV3XVKfXT1xhtvTI7dv39/sp6aqpOkpUuXJuup6bapU6cmx9ZSa4nvWlN9H374YW6tWq0mx1YqlWQdzeHIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc9fpy1btuTWas3jX3vttcn6k08+2dT4Vpo8eXKyvnDhwmR948aNubUHH3wwOfall15K1tEcjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTz/HWqtdR1yrJly5L1Mufxaxk1Kn186O7ubvhvDwwMJOtffPFFsn7eeec1vG9w5AfCIvxAUIQfCIrwA0ERfiAowg8ERfiBoGrO85vZFEmbJE2Q5JLWufsaM7tY0lZJ3ZJ6Jc1x97+2rtVyLV68OLe2atWq5Ni77rorWZ87d26yXutz75dddlmy3krTp09veOzevXuT9X379iXr06ZNa3jfqO/IPyjpF+5+taTvS1piZldLWiZpl7tfLmlXdh/AGaJm+N39kLu/kd3+XNJeSZMkzZZ08mtaNkpKL+0CoKOc1nt+M+uW9F1Jf5I0wd0PZaWPNfS2AMAZou7wm9k4Sb+V9HN3/9vwmru7hs4HjDRukZlVzaza39/fVLMAilNX+M1sjIaC/xt3/122+bCZTczqEyX1jTTW3de5e8XdK11dXUX0DKAANcNvZibpaUl73X34ae0dkk5+detCSc8V3x6AVqnnI72zJC2Q9JaZvZlte1jSSknbzOxuSfslzWlNi50h9dHV1NdTS9Ly5cuT9fXr1yfrW7duTdafeuqp3Fqzr7aG3tHlO3r0aMN/u9YS3FdddVXDfxu11Qy/u/9RkuWUf1hsOwDahSv8gKAIPxAU4QeCIvxAUIQfCIrwA0FZrXncIlUqFa9Wq23bX6f46KOPkvVHH300Wa91HUEr1fr/Y+gasHyXXHJJbm337t3JsT09Pck6vqlSqaharab/o2Q48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUMzzd4ATJ04k64ODg8n6s88+m1v75JNPkmMfeuihZP3YsWPJ+j333JOsr127Nrc2ZsyY5FicPub5AdRE+IGgCD8QFOEHgiL8QFCEHwiK8ANB1fO9/WixUaPS/waPHTs2WZ8/f37D+7733nsbHoszG0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqZvjNbIqZvWRmfzazd8zsX7Ptj5nZQTN7M/u5rfXtAihKPRf5DEr6hbu/YWbflvS6me3Maqvd/fHWtQegVWqG390PSTqU3f7czPZKmtTqxgC01mm95zezbknflfSnbNNSM9tjZhvM7KKcMYvMrGpm1f7+/qaaBVCcusNvZuMk/VbSz939b5J+JalH0gwNvTJ4YqRx7r7O3SvuXunq6iqgZQBFqCv8ZjZGQ8H/jbv/TpLc/bC7f+3uJyStlzSzdW0CKFo9Z/tN0tOS9rr7qmHbJw572M8kvV18ewBapZ6z/bMkLZD0lpm9mW17WNI8M5shySX1Slrckg4BtEQ9Z/v/KGmk7wF/ofh2ALQLV/gBQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCMndv387M+iXtH7ZpvKSBtjVwejq1t07tS6K3RhXZ2z+7e13fl9fW8H9j52ZVd6+U1kBCp/bWqX1J9NaosnrjZT8QFOEHgio7/OtK3n9Kp/bWqX1J9NaoUnor9T0/gPKUfeQHUJJSwm9mt5rZ/5nZPjNbVkYPecys18zeylYerpbcywYz6zOzt4dtu9jMdprZe9nvEZdJK6m3jli5ObGydKnPXaeteN32l/1mNlrSu5J+JOmApNckzXP3P7e1kRxm1iup4u6lzwmb2Y2Sjkja5O7XZNv+TdKn7r4y+4fzInd/qEN6e0zSkbJXbs4WlJk4fGVpSbdLukslPneJvuaohOetjCP/TEn73P0Ddz8uaYuk2SX00fHc/RVJn56yebakjdntjRr6n6ftcnrrCO5+yN3fyG5/LunkytKlPneJvkpRRvgnSfrLsPsH1FlLfrukP5jZ62a2qOxmRjAhWzZdkj6WNKHMZkZQc+XmdjplZemOee4aWfG6aJzw+6br3f17kn4iaUn28rYj+dB7tk6arqlr5eZ2GWFl6b8r87lrdMXropUR/oOSpgy7Pznb1hHc/WD2u0/SdnXe6sOHTy6Smv3uK7mfv+uklZtHWllaHfDcddKK12WE/zVJl5vZd8xsrKS5knaU0Mc3mNn52YkYmdn5kn6szlt9eIekhdnthZKeK7GXf9ApKzfnrSytkp+7jlvx2t3b/iPpNg2d8X9f0iNl9JDT12WS/if7eafs3iRt1tDLwK80dG7kbkmXSNol6T1J/yXp4g7q7T8kvSVpj4aCNrGk3q7X0Ev6PZLezH5uK/u5S/RVyvPGFX5AUJzwA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8DTP2TuPuWrJcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First Image:\")\n",
    "_ = plt.imshow(X_train[0].reshape(28, 28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Image:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Second Image:\")\n",
    "_ = plt.imshow(X_train[1].reshape(28, 28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "The first two labels in the training set are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Label: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Label: {Y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Label: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Second Label: {Y_train[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Here we attempt to use linear discriminant analysis to classify the MNIST digits.\n",
    "\n",
    "### Part A\n",
    "\n",
    "We create a `LinearDiscriminatAnalysis` model using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model to the data and record training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "lda_model.fit(X_train, Y_train)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Train Time: 4.187921299948357s\n"
     ]
    }
   ],
   "source": [
    "print(f\"LDA Train Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Using the fitted model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test Accuracy: 0.8643333333333333\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"LDA Test Accuracy: {lda_model.score(X_test, Y_test)}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Prediction Time: 0.012812700006179512s\n"
     ]
    }
   ],
   "source": [
    "print(f\"LDA Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Here we attempt to use quadratic discriminant analysis to classify MNIST digits.\n",
    "\n",
    "### Part A\n",
    "\n",
    "We create a `QuadraticDiscriminantAnalysis` model using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model to the data and record training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "qda_model.fit(X_train, Y_train)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Train Time: 4.9459744999185205s\n"
     ]
    }
   ],
   "source": [
    "print(f\"QDA Train Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Using the fitted model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Test Accuracy: 0.205\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"QDA Test Accuracy: {qda_model.score(X_test, Y_test)}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Prediction Time: 0.47546149999834597s\n"
     ]
    }
   ],
   "source": [
    "print(f\"QDA Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 \n",
    "\n",
    "Here we attempt to use logistic regression to classify MNIST digits.\n",
    "\n",
    "### Part A\n",
    "\n",
    "We create a `LogisticRegression` model using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(penalty='l1', C=1.0, tol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model to the data and record training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "log_model.fit(X_train, Y_train)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Train Time: 3.5321534998947755s\n"
     ]
    }
   ],
   "source": [
    "print(f\"LR Train Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Using the fitted model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Test Accuracy: 0.9153333333333333\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"LR Test Accuracy: {log_model.score(X_test, Y_test)}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Prediction Time: 0.014556400012224913s\n"
     ]
    }
   ],
   "source": [
    "print(f\"LR Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Here we attempt to use k-nearest neighbors to classify MNIST digits.\n",
    "\n",
    "### Part A\n",
    "\n",
    "We create a `KNeighborsClassifier` model using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1, algorithm='kd_tree', metric='minkowski', p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model to the data and record training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "knn_model.fit(X_train, Y_train)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Time: 2.7918500000378117s\n"
     ]
    }
   ],
   "source": [
    "print(f\"KNN Training Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Using the fitted model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy: 0.959\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"KNN Test Accuracy: {knn_model.score(X_test, Y_test)}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Prediction Time: 87.20465970004443s\n"
     ]
    }
   ],
   "source": [
    "print(f\"KNN Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Here we take a look at the training accuracy of the k-nearest neighbors model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"KNN Training Accuracy: {knn_model.score(X_train, Y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compare it with the training accuracy of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy: 0.9318787878787879\n"
     ]
    }
   ],
   "source": [
    "print(f\"LR Training Accuracy: {log_model.score(X_train, Y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "It makes sense that the training accuracy of the k-nearest neighbors model should be 100\\% as the data set is the model. That is, since we have seen all the training images before, the nearest neighbor will be itself. Therefore, it should predict prefectly on seen images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "Once again, since the data set is the model for k-nearest neighbors, the fit procedure just needs to store the data in an efficient manner. No (really) complex computations are performed on the data, it is just retained.\n",
    "\n",
    "On the other hand, in the prediction phase, the model needs to search the provided data to find the closest neighbors. Even though the data is stored efficiently, it still takes time to find the closest neigbors (especially the more data one has)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F\n",
    "\n",
    "Here we try out different combinations of parameters for k-nearest neighbors models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({ \n",
    "    'n_neighbors': [ 1, 2 ], \n",
    "    'p': [ 2, 3 ], \n",
    "    'algorithm': [ 'kd_tree' ],\n",
    "    'metric': [ 'minkowski' ]\n",
    "})\n",
    "knn_models = []\n",
    "train_times = []\n",
    "validation_accuracies = []\n",
    "\n",
    "for kwargs in param_grid:\n",
    "    \n",
    "    # Create New Model\n",
    "    knn_models.append(KNeighborsClassifier(**kwargs))\n",
    "    \n",
    "    # Fit Model to Data\n",
    "    start = timer()\n",
    "    knn_models[-1].fit(X_train, Y_train)\n",
    "    end = timer()    \n",
    "    train_times.append(end - start)\n",
    "    \n",
    "    # Compute Validation Accuracy\n",
    "    validation_accuracies.append(knn_models[-1].score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part G\n",
    "\n",
    "Using the validation accuracies, we can get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = np.argmax(validation_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we know the best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN: {'p': 3, 'n_neighbors': 1, 'metric': 'minkowski', 'algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best KNN: {param_grid[best_knn]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine how long it took to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Training Time: 2.3914602000731975s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best KNN Training Time: {train_times[best_knn]}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part H\n",
    "\n",
    "Using the best model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Test Accuracy: 0.9613333333333334\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"Best KNN Test Accuracy: {knn_models[best_knn].score(X_test, Y_test)}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Prediction Time: 1308.0901673999615s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best KNN Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Here we attempt to use locality sensitive hashing to to classify MNIST digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin our validation process, we define a function to score a locality sensitive hashing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh_score(lsh_model, Y_train, X_test, Y_test):\n",
    "    \"\"\"Given a locality sensitive hashing model and some data,\n",
    "    computes the accuracy.\n",
    "    \n",
    "    Args:\n",
    "        lsh_model (LSHForest): An approximate nearest neighbor \n",
    "            model using LSH forest.\n",
    "        Y_train (ndarray): Labels from training data used to\n",
    "            build the lsh_model.\n",
    "        X_test (ndarray): Testing samples.\n",
    "        Y_test (ndarray): True labels for testing samples.\n",
    "        \n",
    "    Returns:\n",
    "        float: Mean accuracy of predictions with respect to \n",
    "            true labels.\n",
    "            \n",
    "    \"\"\"\n",
    "    _, k_neighbors = lsh_model.kneighbors(X_test)\n",
    "    Y_pred, _ = mode(Y_train[k_neighbors], axis=1)\n",
    "    \n",
    "    return accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try out several different parameters for our locality sensitive hashing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({ \n",
    "    'n_estimators': [ 20, 40, 80 ], \n",
    "    'n_candidates': [ 10, 20 ], \n",
    "    'n_neighbors': [ 1, 3, 5 ] \n",
    "})\n",
    "lsh_models = []\n",
    "train_times = []\n",
    "validation_accuracies = []\n",
    "\n",
    "for kwargs in param_grid:\n",
    "    \n",
    "    # Create New Model\n",
    "    lsh_models.append(LSHForest(**kwargs)) \n",
    "    \n",
    "    # Fit Model to Data\n",
    "    start = timer()\n",
    "    lsh_models[-1].fit(X_train, Y_train)\n",
    "    end = timer()\n",
    "    train_times.append(end - start)\n",
    "    \n",
    "    # Compute Validation Accuracy\n",
    "    validation_accuracies.append(lsh_score(lsh_models[-1], Y_train, X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the validation accuracies, we can find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lsh = np.argmax(validation_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we know the best parametersfor the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LSH: {'n_neighbors': 3, 'n_estimators': 80, 'n_candidates': 10}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best LSH: {param_grid[best_lsh]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine how long it took to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LSH Traing Time: 8.270534699899144s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best LSH Traing Time: {train_times[best_lsh]}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LSH Test Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"Best LSH Test Accuracy: {lsh_score(lsh_models[best_lsh], Y_train, X_test, Y_test)}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LSH Prediction Time: 108.84070020006038s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best LSH Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It certainly seems like this method is faster with predictions, although training times are a little slower. It also seems like the difference in accuracy is only minimal and it still outperforms all other models considered up until this point. Therefore, I think it would be useful to use approximate k-nearest neighbors. This is especially true if there exists a more performant implementation of approximate k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Here we attempt to use a simple neural network to classify MNIST digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a label encoder to represent labels using one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False).fit(Y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create and compile a simple neural network model using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential([\n",
    "    Dense(512, input_shape=(784,), activation=relu),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation=softmax)\n",
    "])\n",
    "\n",
    "dnn_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this model, we fit it to the data and record the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_one_hot = one_hot_encoder.transform(Y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "dnn_model.fit(X_train, Y_train_one_hot, epochs=5, verbose=0)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Traing Time: 19.167890299926512s\n"
     ]
    }
   ],
   "source": [
    "print(f\"DNN Traing Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fitted model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_one_hot = one_hot_encoder.transform(Y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Test Accuracy: 0.9646666646003723\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"DNN Test Accuracy: {dnn_model.evaluate(X_test, Y_test_one_hot, verbose=0)[1]}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Prediction Time: 0.2821739000501111s\n"
     ]
    }
   ],
   "source": [
    "print(f\"DNN Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "Here we attempt to use a convolutional neural network to classify MNIST digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a method which defines the graph of our model in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    input_layer = tf.reshape(\n",
    "        tensor=features['x'], \n",
    "        shape=(-1, 28, 28, 1))\n",
    "\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv1, \n",
    "        pool_size=(2, 2),\n",
    "        strides=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=(5, 5),\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=(2, 2), \n",
    "        strides=2)\n",
    "\n",
    "    flatten1 = tf.reshape(\n",
    "        tensor=pool2, \n",
    "        shape=(-1, 7 * 7 * 64))\n",
    "    \n",
    "    dense1 = tf.layers.dense(\n",
    "        inputs=flatten1, \n",
    "        units=1024, \n",
    "        activation=tf.nn.relu)\n",
    "        \n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1, \n",
    "        rate=0.4, \n",
    "        training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=dropout1, \n",
    "        units=10)\n",
    "\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(\n",
    "            input=logits, \n",
    "            axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(\n",
    "            logits, \n",
    "            name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            predictions=predictions)\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels=labels, \n",
    "        logits=logits)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            loss=loss, \n",
    "            train_op=train_op)\n",
    "\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, \n",
    "            predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss, \n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this model function, we compile our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.estimator.Estimator(model_fn=cnn_model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model to the data and record the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={ \"x\": X_train },\n",
    "    y=Y_train.astype(np.int32),\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "cnn_model.train(input_fn=train_input_fn, steps=1500)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Traing Time: 469.696110400022s\n"
     ]
    }
   ],
   "source": [
    "print(f\"CNN Traing Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fitted model, we want to score the test data set (i.e. get the accuracy of the model) and record the prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={ \"x\": X_test },\n",
    "    y=Y_test.astype(np.int32),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Test Accuracy: 0.809333324432373\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print(f\"CNN Test Accuracy: {cnn_model.evaluate(input_fn=eval_input_fn)['accuracy']}\")\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Prediction Time: 4.0268184000160545s\n"
     ]
    }
   ],
   "source": [
    "print(f\"CNN Prediction Time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it seems like the simple neural network had the highest accuracy and the most computational efficiency. K-nearest neighbors did come close on accuracy, but it had very poor efficiency. Although the approximate k-nearest neighbors improved on this efficiency, it came at a reduction in accuracy. The convolutional neural network took a significant amount of time to train and its accuracy wasn't even as good as a simple neural network. With more complex images (and more training time), I would assume the convolutional neural network would surpass the accuracy of a simple neural network and k-nearest neighbors. Lastly, all of these models out-performed simple statistical methods like LDA, QDA, and logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
