{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.S077 Problem Set 4\n",
    "\n",
    "## Problem 4-3\n",
    "\n",
    "Parameters for generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "n = 100\n",
    "p = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent $\\beta$ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.linspace(0.01, 0.50, p).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariate matrix $\\mathbb{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_XX(n, p):\n",
    "    \"\"\"Computes the covariate matrix of $n$ samples each with $p$ features.\n",
    "    All are drawn from the standard normal distribution.\n",
    "    \n",
    "    Args:\n",
    "        n (int): Number of samples to generate.\n",
    "        p (int): Number of features for the samples.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Covariate matrix $n$ by $p$ with standard normal components.\n",
    "        \n",
    "    \"\"\"\n",
    "    return np.random.randn(n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations $y$ using the covariate matrix $\\mathbb{X}$ and latent $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_y(XX, beta):\n",
    "    \"\"\"Using the specified covariate matrix and $\\beta$ parameter, \n",
    "    generate some target values. The noise has variance $\\lVert \\beta\n",
    "    \\rVert_2^2 / 2$.\n",
    "    \n",
    "    Args:\n",
    "        XX (ndarray): An $n$ by $p$ covariate matrix of $x$ values.\n",
    "        beta (ndarray): A $p$ by $1$ vector of $\\beta$ parameters.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: A $n$ by $1$ vector of targets with noise.\n",
    "    \n",
    "    \"\"\"    \n",
    "    n, _ = XX.shape\n",
    "    \n",
    "    return XX @ beta + np.sqrt(beta.T @ beta / 2) * np.random.randn(n, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "Learn the $\\hat{\\beta}$ associated with the generated data using linear regression.\n",
    "\n",
    "$$ \\hat{\\beta} = \\left(\\mathbb{X}^T \\mathbb{X}\\right)^{-1} \\mathbb{X}^T y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_beta_hat(XX, y):\n",
    "    \"\"\"Solve the normal equations for the $\\hat{\\beta}$ that minimizes\n",
    "    the least squares of the provided values.\n",
    "    \n",
    "    Args:\n",
    "        XX (ndarray): An $n$ by $p$ matrix of observations.\n",
    "        y (ndarray): An $n$ by $1$ vector of target values.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: A $p$ by $1$ vector representing $\\hat{\\beta}$.\n",
    "        \n",
    "    \"\"\"\n",
    "    return np.linalg.solve(XX.T @ XX, XX.T @ y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training error for the given $\\hat{\\beta}$.\n",
    "\n",
    "$$ \\frac{1}{n}\\sum_{i = 1}^n\\left(y_i - x_i^T \\hat{\\beta}\\right)^2 = \\frac{1}{n} \\left(y - \\mathbb{X} \\hat{\\beta}\\right)^T \\left(y - \\mathbb{X} \\hat{\\beta}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_err(beta_hat, XX, y):\n",
    "    \"\"\"Computes the training error for the specified $\\hat{\\beta}$\n",
    "    on the provided data.\n",
    "    \n",
    "    Args:\n",
    "        beta_hat (ndarray): A $p$ by $1$ vector of a $\\hat{\\beta}$ to\n",
    "            compute the error.\n",
    "        XX (ndarray): An $n$ by $p$ matrix of observations.\n",
    "        y (ndarray): An $n$ by $1$ vector of target values.\n",
    "    \n",
    "    Returns:\n",
    "        float: The error associated with the $\\hat{\\beta}$ for the\n",
    "            provided data.\n",
    "        \n",
    "    \"\"\"\n",
    "    n, _ = y.shape\n",
    "    \n",
    "    return np.asscalar((1 / n) * (y - XX @ beta_hat).T @ (y - XX @ beta_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run for several trials.\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i = 1}^n\\left(y_i - x_i^T \\hat{\\beta}\\right)^2 \\right] = \\mathbb{E}\\left[\\frac{1}{n} \\left(y - \\mathbb{X} \\hat{\\beta}\\right)^T \\left(y - \\mathbb{X} \\hat{\\beta}\\right)\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_train_err(gen_XX, gen_y, num_trials):\n",
    "    \"\"\"Repeatedly calculates the mean and standard deviation of training \n",
    "    error over several trials by solving for a $\\hat{\\beta}$ on many\n",
    "    different generated samples.\n",
    "    \n",
    "    Args:\n",
    "        gen_XX (func): A function with no parameters returning a set of\n",
    "            observations to train on.\n",
    "        gen_y (func): A function with parameter XX which determines the\n",
    "            matching targets for the generated XX samples.\n",
    "        num_trials (int): Number of times to repeat evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        float: Mean of all training errors across trials.\n",
    "        float: Standard deviation of training errors across trials.\n",
    "    \n",
    "    \"\"\"    \n",
    "    train_err = np.zeros((num_trials, 1))\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "\n",
    "        XX = gen_XX()\n",
    "        y = gen_y(XX)\n",
    "    \n",
    "        beta_hat = fit_beta_hat(XX, y)\n",
    "        \n",
    "        train_err[i, 0] = get_train_err(beta_hat, XX, y)\n",
    "    \n",
    "    return train_err.mean(), train_err.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0663375694690895, 0.21246183638826555)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_train_err(lambda: gen_XX(n, p), lambda XX: gen_y(XX, beta), num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Generate a single new sample $\\tilde{x} \\in \\mathbb{R}^p$.\n",
    "\n",
    "$$ \\tilde{x}_i \\sim \\mathcal{N}\\left(0, 1\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x_tilde(p):\n",
    "    \"\"\"Generates a new sample from a standard normal distribution\n",
    "    with $p$ features.\n",
    "    \n",
    "    Args:\n",
    "        p (int): Number of features for the sample drawn.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: A sample from $\\mathbb{R}^P$ with each component \n",
    "            drawn from the standard normal distribution.\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.random.randn(p, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing error for a single sample $\\tilde{x}$.\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\left(\\tilde{x}^T \\beta - \\tilde{x}^T \\hat{\\beta}\\right)^2\\right] + \\sigma^2 = \\left(\\tilde{x}^T \\beta - \\tilde{x}^T \\hat{\\beta}\\right)^T \\left(\\tilde{x}^T \\beta - \\tilde{x}^T \\hat{\\beta}\\right) + \\frac{\\beta^T \\beta}{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_err(x_tilde, beta, beta_hat):\n",
    "    \"\"\"Calculate the actual test error for a new sample given the\n",
    "    $\\hat{\\beta}$ and the actual $\\beta$.\n",
    "    \n",
    "    Args:\n",
    "        x_tilde (ndarray): A $p$ by $1$ vector to compute the error for\n",
    "        beta (ndarray): A $p$ by $1$ vector of actual $\\beta$.\n",
    "        beta_hat (ndarray): A $p$ by $1$ vector of estimated $\\hat{\\beta}$\n",
    "    \n",
    "    Returns:\n",
    "        float: Actual error for new test point on estimated $\\hat{\\beta}$\n",
    "            given the actual $\\beta$.\n",
    "            \n",
    "    \"\"\"\n",
    "    return np.asscalar((x_tilde.T @ beta - x_tilde.T @ beta_hat).T @ (x_tilde.T @ beta - x_tilde.T @ beta_hat) + (beta.T @ beta) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run for several trials.\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\mathbb{E}\\left[\\left(\\tilde{x}^T \\beta - \\tilde{x}^T \\hat{\\beta}\\right)^2\\right] + \\sigma^2\\right] = \\mathbb{E}\\left[\\left(\\tilde{x}^T \\beta - \\tilde{x}^T \\hat{\\beta}\\right)^T \\left(\\tilde{x}^T \\beta - \\tilde{x}^T \\hat{\\beta}\\right) + \\frac{\\beta^T \\beta}{2}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_test_err(gen_XX, gen_y, gen_x_tilde, beta, num_trials):\n",
    "    \"\"\"Repeatedly computes the actual test error for a new data\n",
    "    point drawn from the original distribution for a set number\n",
    "    of trials.\n",
    "    \n",
    "    Args:\n",
    "        gen_XX (func): A function with no parameters returning a matrix\n",
    "            of observations to train on.\n",
    "        gen_y (func): A function with parameter XX which determines the\n",
    "            matching targets for the generated XX samples.\n",
    "        gen_x_tilde (func): A function with no parameters returning a \n",
    "            new sample point to test error of.\n",
    "        num_trials (int): Number of times to repeat evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        float: Mean of all actual test errors across all trials.\n",
    "        float: Standard deviation of actual test errors across all trials.\n",
    "    \n",
    "    \"\"\"   \n",
    "    test_err = np.zeros((num_trials, 1))\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        XX = gen_XX()\n",
    "        y = gen_y(XX)\n",
    "        \n",
    "        beta_hat = fit_beta_hat(XX, y)\n",
    "        \n",
    "        x_tilde = gen_x_tilde()\n",
    "        \n",
    "        test_err[i, 0] = get_test_err(x_tilde, beta, beta_hat)\n",
    "        \n",
    "    return test_err.mean(), test_err.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.311799299124214, 3.2253003882322964)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_err(lambda: gen_XX(n, p), lambda XX: gen_y(XX, beta), lambda: gen_x_tilde(p), beta, num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the relation specified in the problem, test error is\n",
    "\n",
    "$$ \\lVert \\beta - \\hat{\\beta} \\rVert_2^2 + \\sigma^2 = \\left(\\beta - \\hat{\\beta}\\right)^T \\left(\\beta - \\hat{\\beta}\\right) + \\frac{\\beta^T \\beta}{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closed_form_test_err(beta, beta_hat):\n",
    "    \"\"\"Computes the actual test error between estimated\n",
    "    $\\hat{\\beta}$ and actual $\\beta$ without a new sample\n",
    "    drawn.\n",
    "    \n",
    "    Args:\n",
    "        beta (ndarray): A $p$ by $1$ vector of actual $\\beta$.\n",
    "        beta_hat (ndarray): A $p$ by $1$ vector of estimated $\\hat{\\beta}$\n",
    "    \n",
    "    Returns:\n",
    "        float: Actual error of estimated $\\hat{\\beta}$ given the actual $\\beta$.\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.asscalar((beta - beta_hat).T @ (beta - beta_hat) + (beta.T @ beta) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run for several trials.\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\lVert \\beta - \\hat{\\beta} \\rVert_2^2 + \\sigma^2\\right] = \\mathbb{E}\\left[\\left(\\beta - \\hat{\\beta}\\right)^T \\left(\\beta - \\hat{\\beta}\\right) + \\frac{\\beta^T \\beta}{2}\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_closed_form_test_err(gen_XX, gen_y, beta, num_trials):\n",
    "    \"\"\"Repeatedly computes the actual test error for an estimated\n",
    "    $\\hat{\\beta}$ using closed form which doesn't need a new point\n",
    "    to be drawn from the distribution.\n",
    "    \n",
    "    Args:\n",
    "        gen_XX (func): A function with no parameters returning a matrix\n",
    "            of observations to train on.\n",
    "        gen_y (func): A function with parameter XX which determines the\n",
    "            matching targets for the generated XX samples.\n",
    "        num_trials (int): Number of times to repeat evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        float: Mean of all actual test errors across all trials.\n",
    "        float: Standard deviation of actual test errors across all trials.\n",
    "    \n",
    "    \"\"\"   \n",
    "    test_err = np.zeros((num_trials, 1))\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        XX = gen_XX()\n",
    "        y = gen_y(XX)\n",
    "        \n",
    "        beta_hat = fit_beta_hat(XX, y)\n",
    "        \n",
    "        test_err[i, 0] = get_closed_form_test_err(beta, beta_hat)\n",
    "        \n",
    "    return test_err.mean(), test_err.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.316051607216384, 0.6362305558502975)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_closed_form_test_err(lambda: gen_XX(n, p), lambda XX: gen_y(XX, beta), beta, num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "First, we can compute the leave one out cross validation naively fitting several $\\hat{\\beta}$.\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{i = 1}^n \\left(y_i - \\hat{\\hat{y}}_i\\right)^2 = \\frac{1}{n} \\left(y - \\hat{\\hat{y}}\\right)^T \\left(y - \\hat{\\hat{y}}\\right) $$\n",
    "\n",
    "Where $\\hat{\\hat{y}}_i$ is the predition at $x_i$ using the $\\hat{\\beta}'$ fitted without $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loocv_n(XX, y):\n",
    "    \"\"\"Naively computes the leave one out cross valiation error\n",
    "    by repeatedly training a linear regression model and testing\n",
    "    on the left out point.\n",
    "    \n",
    "    Args:\n",
    "        XX (ndarray): An $n$ by $p$ matrix of observations to\n",
    "            run cross validation on.\n",
    "        y (ndarray): An $n$ by $1$ vector of targets to consider.\n",
    "        \n",
    "    Returns:\n",
    "        float: Leave one out cross validation error for the provided\n",
    "            data computed naively.\n",
    "            \n",
    "    \"\"\"\n",
    "    n, _ = XX.shape\n",
    "    \n",
    "    y_hat_hat = np.zeros((n, 1))\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(LeaveOneOut().split(XX)):\n",
    "        \n",
    "        beta_hat_prime = fit_beta_hat(XX[train_ind], y[train_ind])\n",
    "        \n",
    "        y_hat_hat[i:i + 1, :] = XX[test_ind] @ beta_hat_prime\n",
    "        \n",
    "    return np.asscalar((1 / n) * (y - y_hat_hat).T @ (y - y_hat_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeated for several trials.\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i = 1}^n \\left(y_i - \\hat{\\hat{y}}_i\\right)^2\\right] = \\mathbb{E}\\left[\\frac{1}{n} \\left(y - \\hat{\\hat{y}}\\right)^T \\left(y - \\hat{\\hat{y}}\\right)\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_loocv_n(gen_XX, gen_y, num_trials):\n",
    "    \"\"\"Repeatedly computes the LOOCV error by generating\n",
    "    new data sets and using the naive implementation of\n",
    "    LOOCV and reports mean and standard deviation.\n",
    "    \n",
    "    Args:\n",
    "        gen_XX (func): A function with no parameters returning a matrix\n",
    "            of observations to train on.\n",
    "        gen_y (func): A function with parameter XX which determines the\n",
    "            matching targets for the generated XX samples.\n",
    "        num_trials (int): Number of times to repeat evaluation.\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean of LOOCV errors across all trials.\n",
    "        float: Standard deviation of LOOCV across all trials.\n",
    "    \n",
    "    \"\"\"    \n",
    "    loocv_n = np.zeros((num_trials, 1))\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        XX = gen_XX()\n",
    "        y = gen_y(XX)\n",
    "        \n",
    "        loocv_n[i, 0] = get_loocv_n(XX, y)\n",
    "    \n",
    "    return loocv_n.mean(), loocv_n.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.336055794101643, 0.8821864752999772)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loocv_n(lambda: gen_XX(n, p), lambda XX: gen_y(XX, beta), num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute this more quickly using the closed form definition of leave one out cross validation provided in the problem set,\n",
    "\n",
    "$$ \\mathrm{LOOCV}_n = \\frac{1}{n} \\sum_{i = 1}^n \\left(\\frac{y_i - \\hat{y}_i}{h}\\right)^2 = \\frac{1}{n} \\left(h^{-1}\\left(y - \\mathbb{X} \\hat{\\beta}\\right)\\right)^T \\left(h^{-1}\\left(y - \\mathbb{X} \\hat{\\beta}\\right)\\right) $$\n",
    "\n",
    "Where $h$ is defined as,\n",
    "$$ h_i = 1 - x_i \\left(\\mathbb{X}^T \\mathbb{X}\\right)^{-1} x_i^T $$\n",
    "$$ h = \\left(1 - \\mathbb{X} \\left(\\mathbb{X}^T \\mathbb{X}\\right)^{-1} \\mathbb{X}^T\\right) I $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closed_form_loocv_n(XX, y, beta_hat):\n",
    "    \"\"\"Used the known closed form of LOOCV for linear \n",
    "    regression by reusing existing $\\hat{\\beta}$\n",
    "    \n",
    "    Args:\n",
    "        XX (ndarray): An $n$ by $p$ matrix of observations to\n",
    "            run cross validation on.\n",
    "        y (ndarray): An $n$ by $1$ vector of targets to consider.\n",
    "        beta_hat (ndarray): A $p$ by $1$ vector representing \n",
    "            $\\hat{\\beta}$ calculated from the provided data.\n",
    "        \n",
    "    Returns:\n",
    "        float: LOOCV error of data and $\\hat{\\beta}$ using closed \n",
    "            form.\n",
    "    \n",
    "    \"\"\"\n",
    "    n, _ = XX.shape\n",
    "    \n",
    "    h = (1 - XX @ np.linalg.inv(XX.T @ XX) @ XX.T) * np.eye(n)\n",
    "    \n",
    "    return np.asscalar((1 / n) * (np.linalg.inv(h) @ (y - XX @ beta_hat)).T @ (np.linalg.inv(h) @ (y - XX @ beta_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeated for several trials.\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i = 1}^n \\left(\\frac{y_i - \\hat{y}_i}{h}\\right)^2\\right] = \\mathbb{E}\\left[\\frac{1}{n} \\left(h^{-1}\\left(y - \\mathbb{X} \\hat{\\beta}\\right)\\right)^T \\left(h^{-1}\\left(y - \\mathbb{X} \\hat{\\beta}\\right)\\right)\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_closed_form_loocv_n(gen_XX, gen_y, num_trials):\n",
    "    \"\"\"Repeatedly computes the LOOCV error by generating\n",
    "    new data sets and using the closed form implementation of\n",
    "    LOOCV and reports mean and standard deviation.\n",
    "    \n",
    "    Args:\n",
    "        gen_XX (func): A function with no parameters returning a matrix\n",
    "            of observations to train on.\n",
    "        gen_y (func): A function with parameter XX which determines the\n",
    "            matching targets for the generated XX samples.\n",
    "        num_trials (int): Number of times to repeat evaluation.\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean of LOOCV errors across all trials.\n",
    "        float: Standard deviation of LOOCV across all trials.\n",
    "    \n",
    "    \"\"\"    \n",
    "    loocv_n = np.zeros((num_trials, 1))\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        XX = gen_XX()\n",
    "        y = gen_y(XX)\n",
    "        \n",
    "        beta_hat = fit_beta_hat(XX, y)\n",
    "        \n",
    "        loocv_n[i, 0] = get_closed_form_loocv_n(XX, y, beta_hat)\n",
    "    \n",
    "    return loocv_n.mean(), loocv_n.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.348439837327746, 0.8622992847454757)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_closed_form_loocv_n(lambda: gen_XX(n, p), lambda XX: gen_y(XX, beta), num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "Since there is no reasonable closed form of the $k$-fold cross validation, we implement naively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_cv(XX, y, k):\n",
    "    \"\"\"Computes the k-fold cross validation error on the\n",
    "    provided data.\n",
    "    \n",
    "    Args:\n",
    "        XX (ndarray): An $n$ by $p$ matrix of observations to\n",
    "            run cross validation on.\n",
    "        y (ndarray): An $n$ by $1$ vector of targets to consider.\n",
    "        k (int): Number of splits to make in the data.\n",
    "        \n",
    "    Returns:\n",
    "        float: k-fold cross validation error over the provided data.\n",
    "        \n",
    "    \"\"\"\n",
    "    error = 0\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(KFold(n_splits=k).split(XX)):\n",
    "        \n",
    "        beta_hat_prime = fit_beta_hat(XX[train_ind], y[train_ind])\n",
    "        \n",
    "        error += np.mean((y[test_ind] - XX[test_ind] @ beta_hat_prime) ** 2)\n",
    "        \n",
    "    return error / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_k_fold_cv(gen_XX, gen_y, k, num_trials):\n",
    "    \"\"\"Repeatedly computes the k-fold cross validation error \n",
    "    by generating new data sets and reports mean and standard \n",
    "    deviation.\n",
    "    \n",
    "    Args:\n",
    "        gen_XX (func): A function with no parameters returning a matrix\n",
    "            of observations to train on.\n",
    "        gen_y (func): A function with parameter XX which determines the\n",
    "            matching targets for the generated XX samples.\n",
    "        k (int): Number of splits to make in the data.\n",
    "        num_trials (int): Number of times to repeat evaluation.\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean of k-fold cross validation errors across all trials.\n",
    "        float: Standard deviation of k-fold cross validation errors \n",
    "            across all trials.\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    k_fold_cv = np.zeros((num_trials, 1))\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        XX = gen_XX()\n",
    "        y = gen_y(XX)\n",
    "        \n",
    "        k_fold_cv[i, 0] = get_k_fold_cv(XX, y, k)\n",
    "    \n",
    "    return k_fold_cv.mean(), k_fold_cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.905681067377833, 1.0904601109970298)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_k_fold_cv(lambda: gen_XX(n, p), lambda XX: gen_y(XX, beta), 10, num_trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
